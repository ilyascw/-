{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0dade49f-275f-4ffb-9932-14e7c6582738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bd7b75d-07a3-4342-af02-6f1d5c9036c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#начнём с загрузки данных\n",
    "df = pd.read_csv('_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e4bae78-a6b2-4b2b-b464-6015aad36faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 532823 entries, 0 to 532822\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   gndr                  532823 non-null  int64  \n",
      " 1   brth_yr               532823 non-null  int64  \n",
      " 2   erly_pnsn_flg         532823 non-null  int64  \n",
      " 3   prvs_npf              532823 non-null  int64  \n",
      " 4   ch_north              532823 non-null  int64  \n",
      " 5   gdp_growth_iY         532823 non-null  float64\n",
      " 6   unemployment_rate_iY  532823 non-null  float64\n",
      " 7   inflation_rate_iY     532823 non-null  float64\n",
      " 8   interest_rate_iY      532823 non-null  float64\n",
      " 9   est_pr_iY             532823 non-null  float64\n",
      " 10  summ                  532823 non-null  float64\n",
      "dtypes: float64(6), int64(5)\n",
      "memory usage: 44.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8695bb07-351a-409f-a6c6-1ffa93ad52d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "erly_pnsn_flg\n",
       "0    0.963637\n",
       "1    0.036363\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.erly_pnsn_flg.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b05af6-e485-4b72-92c5-c82b7479e491",
   "metadata": {},
   "source": [
    "Наблюдается довольно серьёзный дисбаланс классов. Требуется что-то с этим сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fdff358-e728-4cab-96b9-8754b74056fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение на признаки и целевую переменную\n",
    "X = df.drop(columns=['erly_pnsn_flg'])  # Признаки\n",
    "y = df['erly_pnsn_flg']  # Целевая переменна"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0d5a9-487a-4ad2-8a4f-0665e03e31a6",
   "metadata": {},
   "source": [
    "Для начала используем различные методы, чтобы избавиться от дисбаланса классов. Это поможет обучить модель, которая будет иметь большую \"насмотренность\". Начнём с разделения на обучающую и тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f122e38-7aa8-4ef1-9152-016a11ee77a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1578cfbc-7f0b-45dc-b9ab-6f64bcb117ba",
   "metadata": {},
   "source": [
    "Посмотрим, получилось ли сохранить баланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "158bf3d6-6900-4f36-80ef-3b84bc6cf9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      " erly_pnsn_flg\n",
      "0    0.963637\n",
      "1    0.036363\n",
      "Name: proportion, dtype: float64\n",
      "Test class distribution:\n",
      " erly_pnsn_flg\n",
      "0    0.963637\n",
      "1    0.036363\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Проверка пропорций в обучающей и тестовой выборках\n",
    "print(\"Train class distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"Test class distribution:\\n\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f7bff2-3058-4475-aed5-886cc46c9cce",
   "metadata": {},
   "source": [
    "Сохранить исходный баланс классов получилось, поэтому можно рассмотреть различные методы для снижения дисбаланса классов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081afbc-c36f-4b4c-9dca-169bd96c6ee9",
   "metadata": {},
   "source": [
    "Для начала используем метод SMOTE.\n",
    "SMOTE — это метод повышения представительности редкого класса в задачах классификации с несбалансированными классами.\n",
    "\n",
    "Он позволяет создать синтетические экземпляры для наименее представленного класса.\n",
    "\n",
    "В отличие от простого увеличения данных (oversampling), SMOTE создаёт новые, уникальные экземпляры, что помогает модели лучше обобщать.\n",
    "Новый экземпляр сохраняет некоторые свойства оригинальных данных, что позволяет модели извлекать больше информации.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97a5fc3a-2b53-4fe0-bc1f-9e33d3457122",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy=0.5, k_neighbors=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e2624ef-3db0-4378-b6ab-b3a8517924bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применение SMOTE к обучающей выборке\n",
    "X_resampled_smote, y_resampled_smote = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77562d78-20d9-466e-b71a-8a0fd0f61fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Баланс классов после метода SMOTE:\n",
      " erly_pnsn_flg\n",
      "0    0.666667\n",
      "1    0.333333\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Проверка нового распределения классов в обучающей выборке\n",
    "print(\"Баланс классов после метода SMOTE:\\n\", y_train_balanced.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bfce3f-2bf5-42ea-95e0-3f0241e3d56f",
   "metadata": {},
   "source": [
    "Попробуем применить Random Undersmpling на SMOTE-выборку.\n",
    "Нам это может помочь сохранить в классе большинства важную информацию, при условии что в классе меньшинства будет больше наблюдений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2da27d41-3402-49db-ae9b-d84c24d747a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Undersampling, у нас уже есть SMOTE-выборка, её и передаём\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled_smote_rus, y_resampled_smote_rus = rus.fit_resample(X_resampled_smote, y_resampled_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a842d13e-12be-4fc1-a9a0-9b6f159a4297",
   "metadata": {},
   "source": [
    "Попробуем применить Cluster Centroids.\n",
    "Метод кластеризации группирует наблюдения из класса большинства, и затем выбираются центры кластеров как репрезентативные примеры. \n",
    "Это позволяет сохранить важную информацию при уменьшении числа наблюдений.\n",
    "Удаление наблюдений на основе кластеризации может помочь исключить шумные данные и выбросы, которые могут мешать обучению модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48f4855e-edbb-4077-b5a1-884d862ced09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster Centroids\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_resampled_cc, y_resampled_cc = cc.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9b72a7-9892-4b0d-a42d-1cfd1be7c7de",
   "metadata": {},
   "source": [
    "SMOTEENN (SMOTE + Edited Nearest Neighbors).\n",
    "SMOTE создает синтетические наблюдения для класса меньшинства, а Edited Nearest Neighbors очищает выборку, удаляя шумные наблюдения и выбросы. Это может привести к более чистым данным для обучения модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cbefc734-f8d0-4604-87e5-f6536ff409fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled_smote_enn, y_resampled_smote_enn = smote_enn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa21a9b-1804-4118-8cd2-9dd632f28d26",
   "metadata": {},
   "source": [
    "Посмотрим какой баланс классов получился в результате применения этих методов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b6b7588-dc93-4181-b4ba-5e404c9c72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_proportions(y):\n",
    "    counts = y.value_counts(normalize=True)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d26898c-83d6-41ad-a509-68938f671db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE + Random Undersampling proportions:\n",
      "erly_pnsn_flg\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'SMOTE + Random Undersampling proportions:\\n{class_proportions(y_resampled_smote_rus)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf94e518-b633-40af-9cb8-589ded941795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Centroids proportions:\n",
      "erly_pnsn_flg\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'Cluster Centroids proportions:\\n{class_proportions(y_resampled_cc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1dad58f-7ca2-4333-880f-5148e254bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTEENN proportions:\n",
      "erly_pnsn_flg\n",
      "1    0.508487\n",
      "0    0.491513\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'SMOTEENN proportions:\\n{class_proportions(y_resampled_smote_enn)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a2b7a2-5cc6-4825-8ba1-60bc660d8742",
   "metadata": {},
   "source": [
    "Теперь у нас на руках более сбалансированная выборка -> обучаем модели и смотрим на результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f5ad8-48b2-4b35-aec3-251ad7693f65",
   "metadata": {},
   "source": [
    "Для модели предполагается сначала подобрать параметры для 3 моделей: LogisticRegression, RandomForestClassifier, XGBClassifier\n",
    "После составить из них ансамбль Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def893b-2e47-4784-a2fa-1ad7a1182bda",
   "metadata": {},
   "source": [
    "Начнём с модели логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e7662-2703-4fa6-8c30-ff4379c30bee",
   "metadata": {},
   "source": [
    "Какие гиперпарметры мы будем учитывать:\n",
    "1. C: Параметр регуляризации - высокие значения C приводят к меньшей регуляризации, а низкие — к более строгой регуляризации.\n",
    "Влияние на модель: при слишком малом C модель может переобучиться (чрезмерно подстраиваться под обучающие данные),\n",
    "а при слишком большом — недообучиться (не улавливать закономерности в данных).\n",
    "2. penalty: Метод регуляризации -\n",
    "L1 (Lasso): Устраняет менее важные признаки, что может привести к разреженной модели.\n",
    "L2 (Ridge): Применяет штраф за большие коэффициенты, но не исключает признаки.\n",
    "elasticnet: Сочетает L1 и L2, полезно, если много коррелирующих признаков.\n",
    "3. solver: Алгоритм оптимизации\n",
    "'lbfgs': Эффективен для больших наборов данных и поддерживает только L2.\n",
    "'saga': Работает с большими наборами данных и поддерживает как L1, так и L2.\n",
    "4.max_iter: Максимальное количество итераций.\n",
    "Описание: Максимальное количество итераций для алгоритма оптимизации.\n",
    "Влияние: Если max_iter слишком мал, алгоритм может не сходиться, особенно при больших данных или сложной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fbb04-2b5a-48a9-903c-fa7802346664",
   "metadata": {},
   "source": [
    "Напишем функцию, куда сможем передавать гипермараметры, которые будут использоваться гридсерчем для проверки модели. Так будет удобнее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "50306bc1-6e56-46bc-8203-64b59b250cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LogReg(X_resampled, y_resampled, C=[0.001, 0.01, 0.1, 1, 10, 100], \n",
    "                 penalty=['elasticnet'], l1_ratio=[0.1, 0.5, 0.9, 1], solver=['saga'], max_iter=[100, 200, 300, 400, 500],\n",
    "                 scoring = 'roc_auc'):\n",
    "    \"\"\"\n",
    "    Обучает модель логистической регрессии с использованием GridSearchCV для подбора гиперпараметров.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    X_resampled : array-like, shape (n_samples, n_features)\n",
    "        Обучающие данные после балансировки (признаки).\n",
    "        \n",
    "    y_resampled : array-like, shape (n_samples,)\n",
    "        Целевые переменные после балансировки (метки классов).\n",
    "        \n",
    "    C : list, optional (default=[0.001, 0.01, 0.1, 1, 10, 100])\n",
    "        Гиперпараметр регуляризации. Определяет, насколько сильно будет применяться \n",
    "        регуляризация. Чем меньше значение, тем сильнее регуляризация.\n",
    "\n",
    "    penalty : list, optional (default=['elasticnet'])\n",
    "        Тип регуляризации, которая будет использоваться в модели. Доступные значения \n",
    "        включают 'l1', 'l2', и 'elasticnet'. При использовании 'elasticnet' требуется \n",
    "        указать l1_ratio.\n",
    "        \n",
    "    l1_ratio : list, optional (default=[0.1, 0.5, 0.9, 1])\n",
    "        Соотношение между L1 и L2 регуляризацией. Значения от 0 (только L2) до 1 (только L1).\n",
    "        Этот параметр игнорируется, если penalty не равен 'elasticnet'.\n",
    "        \n",
    "    solver : list, optional (default=['saga'])\n",
    "        Алгоритм оптимизации, который будет использоваться для обучения модели. \n",
    "        Для 'elasticnet' необходимо использовать 'saga'.\n",
    "        \n",
    "    max_iter : list, optional (default=[100, 200, 300, 400, 500])\n",
    "        Максимальное количество итераций для алгоритма оптимизации.\n",
    "        \n",
    "    scoring : str, optional (default='roc_auc')\n",
    "        Метрика, используемая для оценки модели. Поддерживаемые значения включают \n",
    "        'roc_auc', 'accuracy', 'f1', и другие. Это значение будет использоваться \n",
    "        в качестве критерия для подбора гиперпараметров.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    -----------------------\n",
    "    grid_search : GridSearchCV\n",
    "        Объект GridSearchCV, содержащий информацию о лучших параметрах и оценках \n",
    "        модели.\n",
    "    \"\"\"\n",
    "    \n",
    "    if penalty == ['elasticnet']:\n",
    "        param_grid = {\n",
    "            'C': C,\n",
    "            'penalty': penalty,  \n",
    "            'l1_ratio': l1_ratio,  # Соотношение L1 и L2\n",
    "            'solver': solver,  \n",
    "            'max_iter': max_iter  \n",
    "        }\n",
    "    else:\n",
    "        param_grid = {\n",
    "        'C': C,\n",
    "        'penalty': penalty,  \n",
    "        'solver': solver,  \n",
    "        'max_iter': max_iter  \n",
    "    }\n",
    "    \n",
    "    # Создаем экземпляр GridSearch\n",
    "    grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, scoring=scoring, n_jobs=-1)  # Используем n_jobs=-1 для параллельного выполнения\n",
    "    \n",
    "    # Обучение\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    #возвращаем модель\n",
    "    return grid_search\n",
    "\n",
    "def print_bestparams(gr_sr): # Лучшие параметры\n",
    "    print(f\"Лучшие параметры для логистической регрессии: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec1549-cfa1-493c-b566-9b4e207dcd71",
   "metadata": {},
   "source": [
    "Обучим на датасете random undersampling + smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "470142b1-92ab-45e6-b6e2-f2c9a0d0f028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#используем функцию, которую написали ранее для того чтобы обучить логистическую регрессию на датасете random undersampling + smote\n",
    "#grid_model_smote_rus = train_LogReg(X_resampled_smote_rus, y_resampled_smote_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bc598ef5-df84-4ef0-b1a5-156f67d2cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = grid_model_smote_rus.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "96e03b14-babe-4684-b9a0-0de451fa9f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший roc_auc: 0.9845\n"
     ]
    }
   ],
   "source": [
    "#print(f\"Лучший roc_auc: {grid_model_smote_rus.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "02b16b76-d24f-4ff2-9556-f8790032a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98659  4031]\n",
      " [  121  3754]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98    102690\n",
      "           1       0.48      0.97      0.64      3875\n",
      "\n",
      "    accuracy                           0.96    106565\n",
      "   macro avg       0.74      0.96      0.81    106565\n",
      "weighted avg       0.98      0.96      0.97    106565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print(confusion_matrix(y_test, y_pred))\n",
    "#print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d86255a7-32bb-43c2-a27a-6a10de0b3ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('grid_model_smote_rus.pkl', 'wb') as file:\n",
    "    pickle.dump(grid_model_smote_rus, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dbb329-5eaf-4cea-87f2-63003aaffae6",
   "metadata": {},
   "source": [
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4f968be3-49b0-4db4-b83f-38c81283d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#используем функцию c другими параметрами, чтобы обучить на этом том же датасете + используем стандартизацию\n",
    "scaler = StandardScaler()\n",
    "grid_model_smote_rus_L1regularization = train_LogReg(scaler.fit_transform(X_resampled_smote_rus), (y_resampled_smote_rus), C=[0.001, 0.01, 0.1, 1, 10, 100], \n",
    "                 penalty=['l1'], solver=['liblinear'], max_iter=[100, 200, 300, 400],\n",
    "                 scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b5da4d6-0e18-4d97-8086-f07c82c9cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model_smote_rus_L1regularization.best_estimator_.predict(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b6a1a28c-f48d-41d7-b84c-0076a2ed1487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший f1: 0.9937\n"
     ]
    }
   ],
   "source": [
    "print(f\"Лучший f1: {grid_model_smote_rus_L1regularization.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d4d22f60-a816-4960-849a-9383724d5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102106    584]\n",
      " [    35   3840]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    102690\n",
      "           1       0.87      0.99      0.93      3875\n",
      "\n",
      "    accuracy                           0.99    106565\n",
      "   macro avg       0.93      0.99      0.96    106565\n",
      "weighted avg       0.99      0.99      0.99    106565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))#лучшая модель\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0b3ed394-22a4-4bd1-a03b-3e219815b83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('grid_model_smote_rus_l12_saga.pkl', 'wb') as file:\n",
    "    pickle.dump(grid_model_smote_rus_L1regularization, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d55aac-219e-4748-b494-cf42918443c9",
   "metadata": {},
   "source": [
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "525f10d8-2a20-4f5d-a9a7-0715ebb27db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_smote_rus_l12_saga = train_LogReg(scaler.fit_transform(X_resampled_smote_rus), y_resampled_smote_rus, C=[0.001, 0.01, 0.1, 1, 10, 100], \n",
    "                 penalty=['l1', 'l2'], solver=['saga'], max_iter=[600, 400],\n",
    "                 scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2a5e0bb0-3a56-45de-a599-567a880d15ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model_smote_rus_l12_saga.best_estimator_.predict(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a75409b2-3d00-4121-b95d-d99d078f3b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102109    581]\n",
      " [    34   3841]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00    102690\n",
      "           1       0.87      0.99      0.93      3875\n",
      "\n",
      "    accuracy                           0.99    106565\n",
      "   macro avg       0.93      0.99      0.96    106565\n",
      "weighted avg       0.99      0.99      0.99    106565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aba762-ff48-4392-b551-15609f9cff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('grid_model_smote_rus_L1regularization.pkl', 'wb') as file:\n",
    "    pickle.dump(grid_model_smote_rus_L1regularization, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89adb57b-3975-4193-9ed2-bbd1a1cdfc1b",
   "metadata": {},
   "source": [
    "Обучим на датасете random Cluster Centroids, c метрикой roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a66bbda-0c09-4900-b613-2dd69217b12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "grid_model_cc_L2regularization = train_LogReg(X_resampled_cc, y_resampled_cc, C=[0.001, 0.01, 0.1, 1, 10, 25], \n",
    "                 penalty=['l2'], solver=['lbfgs'], max_iter=[100, 200, 300, 400],\n",
    "                 scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e0103755-0adc-4d3b-976b-0959c716da3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model_cc_L2regularization.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3df45ec6-1f09-40ae-a4eb-17aa6f601857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61381 41309]\n",
      " [  710  3165]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.60      0.75    102690\n",
      "           1       0.07      0.82      0.13      3875\n",
      "\n",
      "    accuracy                           0.61    106565\n",
      "   macro avg       0.53      0.71      0.44    106565\n",
      "weighted avg       0.96      0.61      0.72    106565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5514cf30-746b-4dfd-8328-f261be77e3a9",
   "metadata": {},
   "source": [
    "теперь с метрикой f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5dff935f-ee7f-4a8d-8f20-ff2460388863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "grid_model_cc_L2regularization_f1 = train_LogReg(X_resampled_cc, y_resampled_cc, C=[0.001, 0.01, 0.1, 1, 10, 25], \n",
    "                 penalty=['l2'], solver=['lbfgs'], max_iter=[300, 400, 500],\n",
    "                 scoring = 'f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d8fd346-83e8-42b1-aec8-3f2c3c983139",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model_cc_L2regularization_f1.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1895e7e8-dde8-4d24-9da2-dc502e3adec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[61716 40974]\n",
      " [  698  3177]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.60      0.75    102690\n",
      "           1       0.07      0.82      0.13      3875\n",
      "\n",
      "    accuracy                           0.61    106565\n",
      "   macro avg       0.53      0.71      0.44    106565\n",
      "weighted avg       0.96      0.61      0.73    106565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd28471c-fbc5-4f9f-9af9-6f7fea3d4ca4",
   "metadata": {},
   "source": [
    "Обучим на датасете SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e308f437-cf82-4bab-9108-d22034b5a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\conda\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_model_SMOTEENN_L12regularization = train_LogReg(X_resampled_cc, y_resampled_cc, C=[0.001, 0.01, 0.1, 1, 10, 25], \n",
    "                 penalty=['l1', 'l2'], solver=['saga'], max_iter=[100, 200, 300, 400],\n",
    "                 scoring = 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0badebac-7d2f-4188-a432-61f0d39546f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model_SMOTEENN_L12regularization.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "98507476-4370-4e1e-bdcc-c566c785d8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99479  3211]\n",
      " [  364  3511]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    102690\n",
      "           1       0.52      0.91      0.66      3875\n",
      "\n",
      "    accuracy                           0.97    106565\n",
      "   macro avg       0.76      0.94      0.82    106565\n",
      "weighted avg       0.98      0.97      0.97    106565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "006f82b4-8f05-4dea-8f84-56c9733af49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('grid_model_SMOTEENN_L12regularization.pkl', 'wb') as file:\n",
    "    pickle.dump(grid_model_SMOTEENN_L12regularization, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "50cffed1-ae00-4c04-88e6-8cf8a15b0360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#проверим по f1, применяя elasticnet регуляризацию + standartscaler\n",
    "grid_model_SMOTEENN_L12regularization_f1 = train_LogReg(scaler.fit_transform(X_resampled_cc), y_resampled_cc, C=[0.001, 0.01, 0.1, 1, 25], \n",
    "                 penalty=['elasticnet'], l1_ratio= [0.1, 0.5, 0.9, 1], solver=['saga'], max_iter=[600, 800],\n",
    "                 scoring = 'f1')#но на самом деле elasticnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "737cd773-6393-4ba0-9588-c4c154763326",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model_SMOTEENN_L12regularization_f1.best_estimator_.predict(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3bbcc07e-3bbf-4589-9285-0135802added",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89727 12963]\n",
      " [   21  3854]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93    102690\n",
      "           1       0.23      0.99      0.37      3875\n",
      "\n",
      "    accuracy                           0.88    106565\n",
      "   macro avg       0.61      0.93      0.65    106565\n",
      "weighted avg       0.97      0.88      0.91    106565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9452557e-33b1-4552-949e-27291aafa2d9",
   "metadata": {},
   "source": [
    "Лучший результат показала модель \"grid_model_smote_rus_L1regularization\", с учётом, что данные подавались на вход стандартизованные. Стандартизация данных в некоторых случаях приводила к ухудшениям результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c12c97-d06f-4ef8-824d-7c0a3b816aee",
   "metadata": {},
   "source": [
    "Перейдём к методу RandomForest, работа с этим методом выстроена в том же порядке, как и для логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "72bbabb4-5921-49af-885e-2a24c4f9c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_RandomForest(X_resampled, y_resampled, n_estimators=[50, 100, 200],\n",
    "                       max_features=['auto', 'sqrt', 'log2'], \n",
    "                       max_depth=[10, 20, 30, 40, 50], \n",
    "                       min_samples_split=[2, 5, 10], \n",
    "                       min_samples_leaf=[1, 2, 4], \n",
    "                       scoring='f1'):\n",
    "    \"\"\"\n",
    "    Обучает модель случайного леса с использованием GridSearchCV для подбора гиперпараметров.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    X_resampled : array-like, shape (n_samples, n_features)\n",
    "        Обучающие данные после балансировки (признаки).\n",
    "        \n",
    "    y_resampled : array-like, shape (n_samples,)\n",
    "        Целевые переменные после балансировки (метки классов).\n",
    "        \n",
    "    n_estimators : list, optional (default=[50, 100, 200])\n",
    "        Количество деревьев в случайном лесе. Большее количество деревьев может улучшить \n",
    "        производительность, но также увеличивает время обучения.\n",
    "        \n",
    "    max_features : list, optional (default=['auto', 'sqrt', 'log2'])\n",
    "        Максимальное количество признаков, которые будут рассматриваться при поиске \n",
    "        наилучшего разделения. Меньшее количество может снизить переобучение.\n",
    "        \n",
    "    max_depth : list, optional (default=[None, 10, 20, 30, 40, 50])\n",
    "        Максимальная глубина дерева. Ограничение глубины дерева может помочь \n",
    "        предотвратить переобучение.\n",
    "        \n",
    "    min_samples_split : list, optional (default=[2, 5, 10])\n",
    "        Минимальное количество образцов, необходимых для разделения узла.\n",
    "        \n",
    "    min_samples_leaf : list, optional (default=[1, 2, 4])\n",
    "        Минимальное количество образцов, необходимых для создания листа.\n",
    "        \n",
    "    scoring : str, optional (default='roc_auc')\n",
    "        Метрика, используемая для оценки модели. Поддерживаемые значения включают \n",
    "        'roc_auc', 'accuracy', 'f1', и другие. Это значение будет использоваться \n",
    "        в качестве критерия для подбора гиперпараметров.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    -----------------------\n",
    "    grid_search : GridSearchCV\n",
    "        Объект GridSearchCV, содержащий информацию о лучших параметрах и оценках \n",
    "        модели.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Создаем сетку гиперпараметров\n",
    "    param_grid = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf\n",
    "    }\n",
    "    \n",
    "    # Создаем экземпляр GridSearch\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), \n",
    "                               param_grid, \n",
    "                               cv=5, \n",
    "                               scoring=scoring, \n",
    "                               n_jobs=-1)  # Используем n_jobs=-1 для параллельного выполнения\n",
    "    \n",
    "    # Обучение\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "\n",
    "    # Возвращаем модель\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3fd7ced4-ba5c-4137-a6a5-81591223486e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.51 MiB for an array with shape (328606,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"D:\\conda\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 880, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 159, in _safe_split\n    y_subset = _safe_indexing(y, indices)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 263, in _safe_indexing\n    return _pandas_indexing(X, indices, indices_dtype, axis=axis)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 44, in _pandas_indexing\n    return X.take(key, axis=axis)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\pandas\\core\\generic.py\", line 4133, in take\n    new_data = self._mgr.take(\n               ^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 893, in take\n    new_labels = self.axes[axis].take(indexer)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\pandas\\core\\indexes\\base.py\", line 1166, in take\n    taken = algos.take(\n            ^^^^^^^^^^^\n  File \"D:\\conda\\Lib\\site-packages\\pandas\\core\\algorithms.py\", line 1239, in take\n    result = arr.take(indices, axis=axis)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 2.51 MiB for an array with shape (328606,) and data type int64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Обучаем модель случайного леса на сбалансированной выборке, \"победившей\" в логистической регрессии\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m grid_model_rf \u001b[38;5;241m=\u001b[39m train_RandomForest(scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_resampled_smote_rus), (y_resampled_smote_rus))\n",
      "Cell \u001b[1;32mIn[130], line 65\u001b[0m, in \u001b[0;36mtrain_RandomForest\u001b[1;34m(X_resampled, y_resampled, n_estimators, max_features, max_depth, min_samples_split, min_samples_leaf, scoring)\u001b[0m\n\u001b[0;32m     58\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), \n\u001b[0;32m     59\u001b[0m                            param_grid, \n\u001b[0;32m     60\u001b[0m                            cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m     61\u001b[0m                            scoring\u001b[38;5;241m=\u001b[39mscoring, \n\u001b[0;32m     62\u001b[0m                            n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Используем n_jobs=-1 для параллельного выполнения\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Обучение\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_resampled, y_resampled)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Возвращаем модель\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grid_search\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error_fast()\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     error_job\u001b[38;5;241m.\u001b[39mget_result(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return_or_raise()\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\conda\\Lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 2.51 MiB for an array with shape (328606,) and data type int64"
     ]
    }
   ],
   "source": [
    "# Обучаем модель случайного леса на сбалансированной выборке, \"победившей\" в логистической регрессии\n",
    "grid_model_rf = train_RandomForest(scaler.fit_transform(X_resampled_smote_rus), (y_resampled_smote_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0048ca0f-550c-4fac-8bb5-471879255aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_model_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m grid_model_rf\u001b[38;5;241m.\u001b[39mpredict(scaler\u001b[38;5;241m.\u001b[39mfit(X_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'grid_model_rf' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred = grid_model_rf.predict(scaler.fit(X_test))#смотрим на результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1a659-69b5-4262-9532-8e6d26f65218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#метрики\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')  # Для бинарной классификации\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(y_test, grid_model_rf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Печатаем метрики\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Дополнительная информация\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_tes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c8054-8a58-4de7-9783-414f839a09e4",
   "metadata": {},
   "source": [
    "Теперь подберём гиперпараметры для модели XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe04064b-c49f-4534-a326-d46055251a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_XGBoost(X_resampled, y_resampled, n_estimators=[100, 200, 300],\n",
    "                  max_depth=[3, 5, 7], learning_rate=[0.01, 0.1, 0.2],\n",
    "                  scoring='roc_auc'):\n",
    "    \"\"\"\n",
    "    Обучает модель XGBoost с использованием GridSearchCV для подбора гиперпараметров.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    \n",
    "    # Создаем экземпляр GridSearch\n",
    "    grid_search = GridSearchCV(XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'), \n",
    "                               param_grid, cv=5, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    # Обучение\n",
    "    grid_search.fit(X_resampled, y_resampled)\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a5b864-68fa-4320-a284-e6bd5e5e3205",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_model_xgb = train_XGBoost(X_resampled_smote, y_resampled_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e53bd-017a-4a2e-94df-fb2ae76bb185",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid_model_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f4b848-1c0a-4186-9cd7-d35570754abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисляем различные метрики\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')  # Для бинарной классификации\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "roc_auc = roc_auc_score(y_test, grid_model_xgb.predict_proba(X_test)[:, 1])\n",
    "\n",
    "# Печатаем метрики\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# Дополнительная информация\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16eb555-b4c4-42f4-97bb-94a1d8c33bb5",
   "metadata": {},
   "source": [
    "Голосование!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a81884-1320-4957-bbc4-5d594ac05d56",
   "metadata": {},
   "outputs": [],
   "source": [
    " voting_clf = VotingClassifier(estimators=models, voting='soft')  # Используем soft voting для вероятностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7743e54-8025-48ef-9731-5d8f2a0e1cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.fit(X_train, y_train)#обучение ансамбля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a82b742-01ef-4651-a50b-ae37ddf22fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказание на тестовых данных\n",
    "y_pred = voting_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe6f59e-de92-4767-93e6-bcceaf276662",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # Дополнительная информация\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e511dee-cd5a-4cac-af3b-554212f76d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_voting_classifier(models, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Обучает VotingClassifier с использованием предоставленных моделей и выводит метрики.\n",
    "\n",
    "    Параметры:\n",
    "    -----------\n",
    "    models : list\n",
    "        Список кортежей с моделями и их именами (например, [(\"log_reg\", model1), (\"rf\", model2), ...]).\n",
    "    \n",
    "    X_train : array-like, shape (n_samples, n_features)\n",
    "        Обучающие данные.\n",
    "    \n",
    "    y_train : array-like, shape (n_samples,)\n",
    "        Целевые переменные для обучающих данных.\n",
    "    \n",
    "    X_test : array-like, shape (n_samples, n_features)\n",
    "        Тестовые данные.\n",
    "    \n",
    "    y_test : array-like, shape (n_samples,)\n",
    "        Целевые переменные для тестовых данных.\n",
    "\n",
    "    Возвращаемое значение:\n",
    "    -----------------------\n",
    "    voting_clf : VotingClassifier\n",
    "        Объект VotingClassifier, содержащий обученную модель.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Создаем VotingClassifier\n",
    "    voting_clf = VotingClassifier(estimators=models, voting='soft')  # Используем soft voting для вероятностей\n",
    "\n",
    "    # Обучение\n",
    "    voting_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Предсказание на тестовых данных\n",
    "    y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "    # Вычисляем и выводим метрики\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='binary')  # Для бинарной классификации\n",
    "    recall = recall_score(y_test, y_pred, average='binary')\n",
    "    f1 = f1_score(y_test, y_pred, average='binary')\n",
    "    roc_auc = roc_auc_score(y_test, voting_clf.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    # Дополнительная информация\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    return voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7812a575-1de2-46b3-bbdb-867516f0a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Нужно передать лучшие модели по итогам подбора гиперпараметров\n",
    "log_reg_model = grid_model_log_reg.best_estimator_  # Лучшая модель логистической регрессии\n",
    "rf_model = grid_model_rf.best_estimator_  # Лучшая модель случайного леса\n",
    "xgb_model = grid_model_xgb.best_estimator_  # Лучшая модель XGBoost\n",
    "\n",
    "# Список моделей для VotingClassifier\n",
    "models = [\n",
    "    ('log_reg', log_reg_model),\n",
    "    ('rf', rf_model),\n",
    "    ('xgb', xgb_model)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdac937-d57b-42d5-b11f-22b2a8513523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обучение VotingClassifier\n",
    "voting_model = train_voting_classifier(models, X_resampled_smote_rus, y_resampled_smote_rus, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095326f8-570b-4bb0-9660-4a3446ec321c",
   "metadata": {},
   "source": [
    "Функция, которая автоматически проверит все созданные модели, и выведет результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcae29e5-e429-401a-bd90-46b92bb66abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28d3cc-8c78-4f1d-9f9b-512d5c12edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = []\n",
    "model_ = []\n",
    "\n",
    "for m in zip(model_name, model): \n",
    "    print(m[0], f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
